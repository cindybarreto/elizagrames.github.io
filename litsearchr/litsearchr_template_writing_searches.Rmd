---
title: "Template for using litsearchr to write searches"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

# Step 1: Conduct scoping search

Conduct your scoping search in any database that allows you to export .ris or .bib files, or any of the databases listed with litsearchr::usable_databases(). 

```{r}
litsearchr::usable_databases()
scoping_directory <- "../BBWO_example/naive_results/"
```

Decide if you want to only search for n-grams (phrases with at least two words) or if you also want to include unigrams (single words). Using n-grams leads to more specific searches and is recommended to get more relevant words, especially for the keywords identified by RAKE. If you're worried about missing important unigrams, a good compromise is to allow unigrams in select_actual_terms(). Change the code in the chunk below if you want different n-gram or frequency settings, then run the entire chunk. 

```{r}
study_import <-
  litsearchr::import_results(directory = scoping_directory)
  
  study_data <-
  litsearchr::remove_duplicates(df = study_import, field = "title", method =
  "quick")
  
  raked_keywords <-
  litsearchr::extract_terms(
  text = paste(study_data$text, collapse = "; "),
  method = "RAKE",
  min_freq = 2,
  ngrams = TRUE,
  n = 2
  )
  
  real_keywords <-
  litsearchr::extract_terms(
  keywords = study_data$keywords,
  method = "tagged",
  min_freq = 2,
  ngrams = TRUE,
  n = 2
  )
  
  all_keywords <- unique(append(raked_keywords, real_keywords))
  
  study_dfm <-
  litsearchr::create_dfm(elements = study_data$text,
  type = "keywords",
  keywords = all_keywords)
  
  study_graph <- litsearchr::create_network(study_dfm,
  min_studies = 3,
  min_occurrences = 3)
  
  plot(
  sort(igraph::strength(study_graph)),
  ylab = "Node strength",
  main = "Ranked node strengths",
  xlab = "Rank",
  type = "l"
  )
```

Look at the plot of ranked node strengths (plotted by the last line of code in the chunk above) and decide how many knots to place for the spline model. Three works fairly well for most graphs, but if your graph has additional change points you want to capture or doesn't look like the graph from the main vignette, you may want to allow more (or fewer) knots.  

```{r}

cutoffs_spline <-
  litsearchr::find_cutoff(
  study_graph,
  method = "spline",
  degrees = 2,
  knot_num = 3,
  diagnostics = TRUE,
  importance_method = "strength"
  )

# alternative that is much quicker

cutoffs_cumulative <-
  litsearchr::find_cutoff(
  study_graph,
  method = "cumulative",
  percent=0.5,
  diagnostics = FALSE,
  importance_method = "strength"
  )
```

Look at the diagnostic plots. Are they showing essentially no trend in the early portions but deviating from zero later on? If there are clear trends early on that deviate from the zero line, you probably need to change the number of knots. Just don't use too many knots because then you're overfitting.

If you're using a cutoff other than the first knot, make a note of it in the spreadsheet and also change cutoffs_spline[1] in the code below. If you're using the cumulative method, you don't need to change anything. Once you're happy with the cutoff, run this chunk of code:

```{r}
reduced_graph <-
  litsearchr::reduce_graph(study_graph, cutoff_strength = cutoffs_spline[1])
  search_terms <-
  litsearchr::get_keywords(reduced_graph,
  savekeywords = FALSE,
  makewordle = FALSE)
  write.csv(search_terms, "./ngram-potential-keywords.csv")
```


# Step 2: Assign keywords to concept groups

Open the file "ngram-potential-keywords.csv" which is saved in your working directory. Change the column names to "group" and "term" then manually assign each term to your concept groups. To assign a keyword to multiple groups, just separate them by a comma (e.g. if you have one group for "ungulate" and one for "grazing" and a term is "deer browsing", in the spreadsheet you would list its group as "ungulate, grazing" so that it appears in both groups).

Save the modified spreadsheet as "ngram-keywords-grouped.csv" in the same directory. Read it in with the code below.

```{r}
grouped_keywords <- read.csv("./ngram-grouped-keywords.csv", stringsAsFactors = FALSE)
```

Now you're going to need to write your own code because it will depend on what your concept groups are and how many you have. Once you have all your groups put together, save them as a list. Use the commented-out text in the code chunk below as an example of how to do this. Note that you can also list any terms you think of that might be relevant to a category and they will be added to your search even if litsearchr did not identify them as a keyword. 

```{r}
# tillage_group <- unique(append(c("no till", "tillage intensity","mechanical soil disturbance"), 
#                       grouped_keywords$term[which(stringr::str_detect(grouped_keywords$group, "tillage"))]))
# soil_group <- unique(append(c("soil organic carbon"), 
#                       grouped_keywords$term[which(stringr::str_detect(grouped_keywords$group, "soil"))]))
# carbon_group <- unique(append(c("soil organic carbon"), 
#                       grouped_keywords$term[which(stringr::str_detect(grouped_keywords$group, "carbon"))]))

# my_search_terms <- list(tillage_group, soil_group, carbon_group)

```

Optionally, get similar terms to the ones you've already included. You'll likely want to save them as a .csv, group them, and then read the .csv back in (see commented out lines below for an example and modify the code to match your concept groups).

```{r}
similar_terms <- litsearchr::get_similar_terms(my_search_terms, graph = study_graph)

# write.csv(similar_terms, "similar_terms.csv")
# new_terms <- read.csv("similar_terms_grouped.csv", stringsAsFactors = FALSE)

# tillage_group <- unique(append(tillage_group, 
#                       new_terms$term[which(stringr::str_detect(new_terms$group, "tillage"))]))
# soil_group <- unique(append(soil_group, 
#                       new_terms$term[which(stringr::str_detect(new_terms$group, "soil"))]))
# carbon_group <- unique(append(carbon_group, 
#                       new_terms$term[which(stringr::str_detect(new_terms$group, "carbon"))]))

# my_search_terms <- list(tillage_group, soil_group, carbon_group)
```


# Step 3: Write Boolean searches

Choose languages to translate your search into from the list displayed by available_languages(). You may also want to consult the graph displaying suggested languages for your discipline (replace disciplines with generic terms that cover your field).

Note that you must have the proper language packs on your computer in order to convert searches; if your computer can't display the characters then you will get an error message about character conversion. Languages that are most likely to fail are Chinese, Japanese, Korean, Gaelic, Thai, and Taiwanese Mandarin. The other character encodings are fairly standard and you most likely already have them on your computer. 

```{r}
disciplines <- c("ecology", "conservation", "biology")

litsearchr::available_languages()

litsearchr::get_language_data(key_topics = disciplines)[1:10, ]

```

Input the languages you decide to write searches in to the chunk below (replacing the current languages as needed). You also need to include your Google Translate API key.

```{r}
search_languages <-
  c("English",
  "Russian",
  "Spanish",
  "Indonesian",
  "French",
  "German")
  
  my_API_key <- readLines("~/Google-Translate-API")

```

Now, you're ready to write your search. Run the code chunk below. The searches will appear in your working directory. This step can take some time depending on how many languages you are translating into. 

```{r}
litsearchr::write_search(
  groupdata = my_search_terms,
  languages = search_languages,
  exactphrase = TRUE,
  stemming = TRUE,
  directory = "./",
  API_key = my_API_key,
  writesearch = FALSE,
  verbose = TRUE
  )
  
```
